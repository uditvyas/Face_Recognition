{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRP_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kURtMJRsxd8b"
      },
      "source": [
        "# **Probability and Random Processes: Assignment 2**\n",
        "This Assignment is based on two algorithms.\n",
        "1. Viola Jones Algorithm for Face Detection\n",
        "2. Method of Eigenfaces for Face Recognition\n",
        "\n",
        "To setup the data and the supporting functions, run the cells to import the libraries and clone the github repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ial2AWpJaGlD"
      },
      "source": [
        "### IMPORTING THE LIBRARIRES ###\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "\n",
        "!git clone --quiet https://github.com/uditvyas/Face_Recognition.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r8t-ptYydoF"
      },
      "source": [
        "# Part 1: Viola Jones Algorithm for Face Detection\n",
        "\n",
        "For this part, we need to extract both the positive and the negative images from the cloned repository. After this, we need to create the info files for both the positive and the negative files. The following code block produce the result.\n",
        "\n",
        "*`NOTE`: Run the next code cell **ONLY if** you wish to reproduce the results of training the Haar Classifier. Otherwise, **the Classifier file is already available in the cloned github repository**.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6uGK-YU3dCt"
      },
      "source": [
        "# Checking if already exists\n",
        "if os.path.exists('/content/pos'):\n",
        "    shutil.rmtree('/content/pos')\n",
        "if os.path.exists('/content/neg'):\n",
        "    shutil.rmtree('/content/neg')\n",
        "\n",
        "# Unzipping the data files\n",
        "!unzip /content/Face_Recognition/negative.zip\n",
        "!unzip /content/Face_Recognition/positive.zip\n",
        "\n",
        "# Creating the data information files\n",
        "def create_pos_n_neg():\n",
        "    for file_type in ['neg','pos']:\n",
        "        \n",
        "        for img in os.listdir(file_type):\n",
        "\n",
        "            if file_type == 'pos':\n",
        "                line = file_type+'/'+img+' 1 0 0 62 47\\n'\n",
        "                with open('pos.lst','a') as f:\n",
        "                    f.write(line)\n",
        "            elif file_type == 'neg':\n",
        "                line = file_type+'/'+img+'\\n'\n",
        "                with open('neg.dat','a') as f:\n",
        "                    f.write(line)\n",
        "create_pos_n_neg()\n",
        "\n",
        "# Creating the Vector File\n",
        "!opencv_createsamples -info pos.lst -num 3240 -w 100 -h 100 -vec positives.vec\n",
        "# Training the Haar Classifier\n",
        "!opencv_traincascade -data data -vec positives.vec -bg neg.dat -numPos 2500 -numNeg 1500 -numStages 2 -w 100 -h 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moXFrHIE6KfZ"
      },
      "source": [
        "Part 2: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9woZzFXyF-3",
        "outputId": "57a2e2e8-0dcf-47ef-8390-9d44db96b45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "### DOWNLOADING THE MIT FACE DATASET AND EXTRACTING THE IMAGES ###\n",
        "\n",
        "### MIT FACE DATASET ###\n",
        "if os.path.exists('/content/pos'):\n",
        "    shutil.rmtree('/content/pos')\n",
        "\n",
        "print(\"Downloading Data....\")\n",
        "!unzip -q /content/Face_Recognition/positive.zip\n",
        "\n",
        "shutil.rmtree('/content/Face_Recognition')\n",
        "\n",
        "################################################################################\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "h = 100\n",
        "w = 100\n",
        "\n",
        "for name in tqdm(os.listdir('/content/pos')):\n",
        "    img = cv2.imread(\"/content/pos/\"+name,cv2.IMREAD_GRAYSCALE)\n",
        "    img = img.flatten()\n",
        "    images.append(img)\n",
        "    label = int(name.split(\".\")[0])//324\n",
        "    labels.append(label)\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\nImages Array: {}\".format(images.shape))\n",
        "print(\"Labels Array: {}\".format(labels.shape))\n",
        "\n",
        "## THE DATASET IS READY FOR DETECTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Data....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3240/3240 [00:00<00:00, 8486.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Images Array: (3240, 10000)\n",
            "Labels Array: (3240,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLzJEp5_aUZM"
      },
      "source": [
        "### SPLITTING THE IMAGES INTO TRAIN AND TEST DATASETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.5)\n",
        "\n",
        "print(\"X_train dimension: {}\".format(X_train.shape))\n",
        "print(\"y_train dimension: {}\".format(y_train.shape))\n",
        "print(\"X_test dimension: {}\".format(X_test.shape))\n",
        "print(\"y_test dimension: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77d-npCHaax-"
      },
      "source": [
        "### CALCULTAING MEAN FACE AND IMPLEMENTING PRINCIPLE COMPONENT ANALYSIS\n",
        "\n",
        "mean_face = np.mean([X_train[i] for i in range(len(X_train))],axis=0)\n",
        "print(\"Mean Face Dimensions:{}\".format(mean_face.shape))\n",
        "\n",
        "normalised_X_train = X_train - mean_face\n",
        "print(\"Normalised Faces Dimensions: {}\".format(normalised_X_train.shape))\n",
        "\n",
        "# cov_matrix = (1/normalised_X_train.shape[0])*np.cov(normalised_X_train)\n",
        "cov_matrix = np.cov(normalised_X_train)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "print(\"Cov Matrix Dimensions: {}\".format(cov_matrix.shape))\n",
        "print(\"Eigenvalues of Cov Dimensions: {}\".format(eigenvalues.shape))\n",
        "print(\"Eigenvectors of Cov Dimensions: {}\".format(eigenvectors.shape))\n",
        "\n",
        "eig_pairs = [(eigenvalues[index], eigenvectors[:,index]) for index in range(len(eigenvalues))]\n",
        "\n",
        "# Sort the eigen pairs in descending order:\n",
        "eig_pairs.sort(reverse=True)\n",
        "sorted_values  = np.array([eig_pairs[index][0] for index in range(len(eigenvalues))])\n",
        "sorted_vectors = np.array([eig_pairs[index][1] for index in range(len(eigenvalues))])\n",
        "\n",
        "print(\"Sorted Eigenvectors Dimensions: {}\".format(sorted_values.shape))\n",
        "print(\"Sorted Eigenvalues Dimensions: {}\".format(sorted_vectors.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcutvFKv0Z-m"
      },
      "source": [
        "### DECIDING THE NUMBER OF PRINCIPLE COMPONENTS\n",
        "\n",
        "# Finding Cumulative Sum of eigenvalues\n",
        "cummulative_sum = np.cumsum(sorted_values)/np.sum(sorted_values)\n",
        "\n",
        "x_axis = range(1,len(sorted_values)+1)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(x_axis, cummulative_sum)\n",
        "plt.xlabel(\"Number of Principle Components\")\n",
        "plt.ylabel(\"Cummulative Variance \")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgbX1ofc1WPT",
        "outputId": "3da2843b-45c4-4fd7-cd07-0071158e9d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "### REDUCING THE DATA ###\n",
        "K = 200\n",
        "\n",
        "reduced_data = np.array(sorted_vectors[:K]).transpose()\n",
        "print(\"Reduced Data Dimensions: {}\".format(reduced_data.shape))\n",
        "\n",
        "final_eigen_vectors = np.dot(normalised_X_train.transpose(),reduced_data)\n",
        "print(\"Final Eigen Vectors Dimensions: {}\".format(final_eigen_vectors.shape))\n",
        "\n",
        "### FINAL EIGENVECTORS ARE READY ###\n",
        "\n",
        "# Finding weights for each training image\n",
        "\n",
        "train_weights = np.array([np.dot(i,final_eigen_vectors) for i in normalised_X_train])\n",
        "print(\"Train Weights Dimensions: {}\".format(train_weights.shape))\n",
        "\n",
        "final_eigen_vectors = np.transpose(final_eigen_vectors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reduced Data Dimensions: (1620, 200)\n",
            "Final Eigen Vectors Dimensions: (10000, 200)\n",
            "Train Weights Dimensions: (1620, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWamnS8GDlFr"
      },
      "source": [
        "def display_compare(test_img,predicted_index,test_index):\n",
        "    test_img = np.reshape(test_img,(-1,100))\n",
        "    actual_label = y_test[test_index]\n",
        "    # print(\"Actual Label: {}\".format(actual_label))\n",
        "    # cv2_imshow(test_img)\n",
        "\n",
        "    predicted_image = np.reshape(X_train[predicted_index],(-1,100))\n",
        "    predicted_label = y_train[predicted_index]\n",
        "    # print(\"Predicted Label: {}\".format(predicted_label))\n",
        "    # cv2_imshow(predicted_image)\n",
        "\n",
        "    if predicted_label == actual_label:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuKknGcB-Gwb",
        "outputId": "9bb6cb07-9cd1-4586-b3ae-cfa8ad011f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "correct = 0\n",
        "for i in tqdm(range(len(X_test))):\n",
        "    img = X_test[i]\n",
        "    norm_img = img - mean_face\n",
        "    weights = np.array([np.dot(norm_img,final_eigen_vectors[k]) for k in range(final_eigen_vectors.shape[0])])\n",
        "    weight_error = train_weights - weights\n",
        "    norms = np.linalg.norm(weight_error,axis = 1)\n",
        "    predicted_index = np.argmin(norms)\n",
        "    correct = correct + display_compare(img,predicted_index,i)\n",
        "print(correct)\n",
        "accuracy = correct*100/(i+1)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1620/1620 [00:10<00:00, 154.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1597\n",
            "Accuracy: 98.58%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVfB9PMdOovB"
      },
      "source": [
        "# !apt-get install libopencv-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-sPbtuFJSJ2"
      },
      "source": [
        "!git clone --quiet https://github.com/uditvyas/Face_Recognition.git\n",
        "!unzip /content/Face_Recognition/negative.zip\n",
        "# !unzip /content/Face_Recognition/positive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iJ84Hx9vEqD"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "def prepare_pos_images():\n",
        "    if not os.path.exists(\"pos\"):\n",
        "        os.mkdir(\"pos\")\n",
        "    else:\n",
        "        print(\"Pos Exists. Deleting Directory\")\n",
        "        shutil.rmtree(\"pos\")\n",
        "        os.mkdir(\"pos\")\n",
        "\n",
        "    img_num = 0\n",
        "    for f in os.listdir('training-synthetic'):\n",
        "        try:\n",
        "            print(f)\n",
        "            img = cv2.imread('training-synthetic/'+f,cv2.IMREAD_GRAYSCALE)\n",
        "            resized_img = cv2.resize(img,(100,100))\n",
        "            cv2.imwrite(\"pos/\"+str(img_num)+\".jpg\",resized_img)\n",
        "            img_num += 1\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "# prepare_pos_images()\n",
        "\n",
        "def prepare_neg_images():\n",
        "    if not os.path.exists(\"neg\"):\n",
        "        os.mkdir(\"neg\")\n",
        "    # else:\n",
        "    #     print(\"Neg Exists. Deleting Directory\")\n",
        "    #     shutil.rmtree(\"neg\")\n",
        "    #     os.mkdir(\"neg\")\n",
        "\n",
        "    # neg_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03183080'\n",
        "    # neg_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03563967'\n",
        "    # neg_link = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04576211'\n",
        "    neg_link = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n01905661'\n",
        "\n",
        "\n",
        "    urls = urllib.request.urlopen(neg_link).read().decode()\n",
        "\n",
        "    img_num = 1520\n",
        "\n",
        "    for i in urls.split(\"\\n\"):\n",
        "        try:\n",
        "            print(i)\n",
        "            dir = '/content/drive/My Drive/:p Sem ki naiya hai Ram ke bharose!!/ES331: Probability and Random Processes/Assignment2_Udit/neg/'\n",
        "            urllib.request.urlretrieve(i,dir+str(img_num)+\".jpg\")\n",
        "            img = cv2.imread(dir+str(img_num)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n",
        "            resized_img = cv2.resize(img,(100,100))\n",
        "            cv2.imwrite(dir+str(img_num)+\".jpg\",resized_img)\n",
        "            img_num+=1\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "prepare_neg_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kFwcWlIRthU"
      },
      "source": [
        "import os\n",
        "def create_pos_n_neg():\n",
        "    for file_type in ['neg','pos']:\n",
        "        \n",
        "        for img in os.listdir(file_type):\n",
        "\n",
        "            if file_type == 'pos':\n",
        "                line = file_type+'/'+img+' 1 0 0 62 47\\n'\n",
        "                with open('pos.lst','a') as f:\n",
        "                    f.write(line)\n",
        "            elif file_type == 'neg':\n",
        "                line = file_type+'/'+img+'\\n'\n",
        "                with open('neg.dat','a') as f:\n",
        "                    f.write(line)\n",
        "create_pos_n_neg()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA5tTRHmKV3Z"
      },
      "source": [
        "!opencv_createsamples -info pos.lst -num 3240 -w 100 -h 100 -vec positives.vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw5qoLtALRY5"
      },
      "source": [
        "!opencv_traincascade -data data -vec positives.vec -bg neg.dat -numPos 2500 -numNeg 1500 -numStages 2 -w 100 -h 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyOBk5k3sHlr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Load data\n",
        "lfw_dataset = fetch_lfw_people(min_faces_per_person=100)\n",
        "num_img = 2588\n",
        "X = []\n",
        "y = []\n",
        "h = 62\n",
        "w = 47\n",
        "\n",
        "# Positive Images and Labels\n",
        "\n",
        "for i in range(num_img):\n",
        "    img = cv2.imread('pos/'+str(i)+'.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "    img = img.flatten()\n",
        "    X.append(img)\n",
        "    y.append(i//324)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "mean_face = np.mean([X[i] for i in range(len(X))],axis=0)\n",
        "print(\"Mean Face Dimensions:{}\".format(mean_face.shape))\n",
        "\n",
        "# _, h, w = lfw_dataset.images.shape\n",
        "# X = lfw_dataset.data\n",
        "# y = lfw_dataset.target\n",
        "# target_names = lfw_dataset.target_names\n",
        "target_names = [str(i) for i in range(10)]\n",
        "\n",
        "# split into a training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "\n",
        "# Compute a PCA \n",
        "n_components = 100\n",
        "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
        "\n",
        "eigenfaces = pca.components_\n",
        "eigenvalues = pca.explained_variance_\n",
        "print(\"Eigenfaces Dimensions: {}\".format(eigenfaces.shape))\n",
        "print(\"Eigenvalues Dimensions: {}\".format(eigenvalues.shape))\n",
        "\n",
        "test = X_test[10]\n",
        "print(\"Test Image Shape: {}\".format(test.shape))\n",
        "\n",
        "weights = np.array([np.dot(eigenfaces[k],test-mean_face) for k in range(n_components)])\n",
        "lin_comb = np.zeros(len(test))\n",
        "for i in range(len(weights)):\n",
        "    lin_comb += weights[i]*eigenfaces[i]\n",
        "print(\"Linear Combination Dimension: {}\".format(lin_comb.shape))\n",
        "\n",
        "# # apply PCA transformation\n",
        "# X_train_pca = pca.transform(X_train)\n",
        "# X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# # train a neural network\n",
        "# print(\"Fitting the classifier to the training set\")\n",
        "# clf = MLPClassifier(hidden_layer_sizes=(1024,), batch_size=256, verbose=True, early_stopping=True).fit(X_train_pca, y_train)\n",
        "\n",
        "# y_pred = clf.predict(X_test_pca)\n",
        "# print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# # Visualization\n",
        "# def plot_gallery(images, titles, h, w, rows=3, cols=4):\n",
        "#     plt.figure(figsize = (10,10))\n",
        "#     for i in range(rows * cols):\n",
        "#         plt.subplot(rows, cols, i + 1)\n",
        "#         plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
        "#         plt.title(titles[i])\n",
        "#         plt.xticks(())\n",
        "#         plt.yticks(())\n",
        " \n",
        "# def titles(y_pred, y_test, target_names):\n",
        "#     for i in range(y_pred.shape[0]):\n",
        "#         pred_name = target_names[y_pred[i]].split(' ')[-1]\n",
        "#         true_name = target_names[y_test[i]].split(' ')[-1]\n",
        "#         yield 'predicted: {0}\\ntrue: {1}'.format(pred_name, true_name)\n",
        " \n",
        "# prediction_titles = list(titles(y_pred, y_test, target_names))\n",
        "# plot_gallery(X_test, prediction_titles, h, w)\n",
        "\n",
        "# eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
        "# plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IK0392V8UWf"
      },
      "source": [
        "# image_label_pairs = list(zip(images,labels))\n",
        "# sorted_pairs = sorted(image_label_pairs,key = lambda x:x[1])\n",
        "# num_classes = np.unique(labels)\n",
        "\n",
        "# X_train = []\n",
        "# X_test = []\n",
        "# y_train = []\n",
        "# y_test = []\n",
        "\n",
        "# count1 = 0\n",
        "# count2 = 0\n",
        "# total = 0\n",
        "# for image,label in sorted_pairs:\n",
        "#     total+=1\n",
        "#     if count1 == 9:\n",
        "#         if count2<2:\n",
        "#             X_test.append(image)\n",
        "#             y_test.append(label)\n",
        "#             count2 += 1\n",
        "        \n",
        "#         else:\n",
        "#             X_train.append(image)\n",
        "#             y_train.append(label)\n",
        "#             count2 = 0\n",
        "#             count1 = 1\n",
        "\n",
        "#     else:\n",
        "#         X_train.append(image)\n",
        "#         y_train.append(label)\n",
        "#         count1+=1\n",
        "# X_train = np.array(X_train)\n",
        "# y_train = np.array(y_train)\n",
        "# X_test = np.array(X_test)\n",
        "# y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8haTiiCA-ky"
      },
      "source": [
        "### EXTRACTING THE IMAGES IN A USABLE FORMAT ###\n",
        "### YALE FACE DATASET ###\n",
        "\n",
        "!wget https://vismod.media.mit.edu/vismod/classes/mas622-00/datasets/YALE.tar.gz\n",
        "!tar -xvf  'YALE.tar.gz'\n",
        "\n",
        "################################################################################\n",
        "\n",
        "if os.path.exists('faces'):\n",
        "    shutil.rmtree('faces')\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "os.mkdir('faces')\n",
        "\n",
        "for name in os.listdir('YALE/faces'):\n",
        "    if not '.pgm' in name:\n",
        "      img = Image.open('YALE/faces/'+name)\n",
        "      h = int(img.size[0]/3)\n",
        "      w = int(img.size[1]/3)\n",
        "      img = img.resize((h,w))\n",
        "      img.save('faces/'+name+'.jpg')\n",
        "      img = cv2.imread('faces/'+name+'.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "      images.append(img.flatten())\n",
        "      labels.append(int(name.split('.')[0][-2:]))\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(\"Images Array: {}\".format(images.shape))\n",
        "print(\"Labels Array: {}\".format(labels.shape))\n",
        "\n",
        "## THE DATASET IS READY FOR DETECTION"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}