{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRP_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kURtMJRsxd8b"
      },
      "source": [
        "# **Probability and Random Processes: Assignment 2**\n",
        "This Assignment is based on two algorithms.\n",
        "1. Viola Jones Algorithm for Face Detection\n",
        "2. Method of Eigenfaces for Face Recognition\n",
        "\n",
        "To setup the data and the supporting functions, run the cells to import the libraries and clone the github repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ial2AWpJaGlD"
      },
      "source": [
        "### IMPORTING THE LIBRARIRES ###\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "\n",
        "!git clone --quiet https://github.com/uditvyas/Face_Recognition.git"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r8t-ptYydoF"
      },
      "source": [
        "# Part 1: Viola Jones Algorithm for Face Detection (Training Haar Classifier)\n",
        "\n",
        "For this part, we need to extract both the positive and the negative images from the cloned repository. After this, we need to create the info files for both the positive and the negative files. The following code block produce the result.\n",
        "\n",
        "**NOTE**: Run the next code cell **ONLY if** you wish to reproduce the results of training the Haar Classifier (training takes approx. 2 hours). Otherwise, **the Classifier file is already available in the cloned github repository**.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6uGK-YU3dCt"
      },
      "source": [
        "# Checking if already exists\n",
        "if os.path.exists('/content/pos'):\n",
        "    shutil.rmtree('/content/pos')\n",
        "if os.path.exists('/content/neg'):\n",
        "    shutil.rmtree('/content/neg')\n",
        "\n",
        "# Unzipping the data files\n",
        "!unzip -q /content/Face_Recognition/negative.zip\n",
        "!unzip -q /content/Face_Recognition/positive.zip\n",
        "\n",
        "# Creating the data information files\n",
        "def create_pos_n_neg():\n",
        "    for file_type in ['neg','pos']:\n",
        "        \n",
        "        for img in os.listdir(file_type):\n",
        "\n",
        "            if file_type == 'pos':\n",
        "                line = file_type+'/'+img+' 1 0 0 62 47\\n'\n",
        "                with open('pos.lst','a') as f:\n",
        "                    f.write(line)\n",
        "            elif file_type == 'neg':\n",
        "                line = file_type+'/'+img+'\\n'\n",
        "                with open('neg.dat','a') as f:\n",
        "                    f.write(line)\n",
        "create_pos_n_neg()\n",
        "\n",
        "if os.path.exists('data'):\n",
        "    shutil.rmtree('data')\n",
        "os.mkdir('data')\n",
        "\n",
        "# This command needs to installed in, if implementing in a local machine\n",
        "# !apt-get install libopencv-dev\n",
        "\n",
        "# Creating the Vector File\n",
        "!opencv_createsamples -info pos.lst -num 3240 -w 100 -h 100 -vec positives.vec\n",
        "# Training the Haar Classifier\n",
        "!opencv_traincascade -data data -vec positives.vec -bg neg.dat -numPos 1500 -numNeg 750 -numStages 4 -w 100 -h 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ce8pEyBHY7i"
      },
      "source": [
        "# Part 2: Detecting faces using the Haar Classifier\n",
        "\n",
        "The below Code block extracts the images from the zip files.\n",
        "\n",
        "After this, the Opencv Cascade Classifier function uses the Haar Classifier (.xml file), which was trained in the above code block.\n",
        "\n",
        "All the images are then passed through the face detector and then are cropped based on the classifier's output. The cropped images are then appended to the final dataset of images and corresponding labels, which are ready to be classified using eigen faces algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9woZzFXyF-3"
      },
      "source": [
        "### EXTRACTING THE IMAGES ###\n",
        "\n",
        "### MIT FACE DATASET ###\n",
        "if os.path.exists('/content/pos'):\n",
        "    shutil.rmtree('/content/pos')\n",
        "\n",
        "print(\"Downloading Data....\")\n",
        "!unzip -q /content/Face_Recognition/positive.zip\n",
        "\n",
        "################################################################################\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "h = 100\n",
        "w = 100\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('/content/Face_Recognition/haarcascade_frontalface_default.xml')\n",
        "\n",
        "for name in tqdm(os.listdir('/content/pos')):\n",
        "    img = cv2.imread(\"/content/pos/\"+name,cv2.IMREAD_GRAYSCALE)\n",
        "    face = list(face_cascade.detectMultiScale(img,1.3,5))\n",
        "    if face:    \n",
        "        face = face[0]\n",
        "        x,y,h,w = face[0],face[1],face[2],face[3],\n",
        "        img = img[y:y+h,x:x+w]\n",
        "        img = cv2.resize(img,(50,50))\n",
        "        img = img.flatten()\n",
        "        images.append(img)\n",
        "        label = int(name.split(\".\")[0])//324\n",
        "        labels.append(label)\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\nFaces Detected in Images Array: {}\".format(images.shape))\n",
        "print(\"Labels of Detected Images: {}\".format(labels.shape))\n",
        "\n",
        "## THE DATASET IS READY FOR DETECTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moXFrHIE6KfZ"
      },
      "source": [
        "NOTE: The program involves an inherent assumption that the Haar Classifier used is 100% accurate. This approach is not a robust method. However, evaluating the accuracy of the Haar classifier is beyond the scope of this assignment.\n",
        "\n",
        "# Part 2: Classification of Detected Faces using Eigenfaces\n",
        "\n",
        "From the detected faces in the above step, we split the images and labels into training and testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLzJEp5_aUZM"
      },
      "source": [
        "### SPLITTING THE IMAGES INTO TRAIN AND TEST DATASETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.20)\n",
        "\n",
        "print(\"X_train dimension: {}\".format(X_train.shape))\n",
        "print(\"y_train dimension: {}\".format(y_train.shape))\n",
        "print(\"X_test dimension: {}\".format(X_test.shape))\n",
        "print(\"y_test dimension: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAC1-h7sLeLY"
      },
      "source": [
        "The below code block does the following -\n",
        "\n",
        "1. Find the mean face\n",
        "2. Normalise the training data\n",
        "3. Find the covariance matrix\n",
        "4. Find the eigenvalues and eigenvectors\n",
        "5. Sort the eigenvectors in the order of decreasing eigenalues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77d-npCHaax-"
      },
      "source": [
        "### CALCULTAING MEAN FACE AND IMPLEMENTING PRINCIPLE COMPONENT ANALYSIS\n",
        "\n",
        "mean_face = np.mean([X_train[i] for i in range(len(X_train))],axis=0)\n",
        "print(\"Mean Face Dimensions:{}\".format(mean_face.shape))\n",
        "\n",
        "normalised_X_train = X_train - mean_face\n",
        "print(\"Normalised Faces Dimensions: {}\".format(normalised_X_train.shape))\n",
        "\n",
        "# cov_matrix = (1/normalised_X_train.shape[0])*np.cov(normalised_X_train)\n",
        "cov_matrix = np.cov(normalised_X_train)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "print(\"Cov Matrix Dimensions: {}\".format(cov_matrix.shape))\n",
        "print(\"Eigenvalues of Cov Dimensions: {}\".format(eigenvalues.shape))\n",
        "print(\"Eigenvectors of Cov Dimensions: {}\".format(eigenvectors.shape))\n",
        "\n",
        "eig_pairs = [(eigenvalues[index], eigenvectors[:,index]) for index in range(len(eigenvalues))]\n",
        "\n",
        "# Sort the eigen pairs in descending order:\n",
        "eig_pairs.sort(reverse=True)\n",
        "sorted_values  = np.array([eig_pairs[index][0] for index in range(len(eigenvalues))])\n",
        "sorted_vectors = np.array([eig_pairs[index][1] for index in range(len(eigenvalues))])\n",
        "\n",
        "print(\"Sorted Eigenvectors Dimensions: {}\".format(sorted_values.shape))\n",
        "print(\"Sorted Eigenvalues Dimensions: {}\".format(sorted_vectors.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5USEiYRL8RL"
      },
      "source": [
        "After the sorting of eigenvalues and eigenvectors is completed, we now plot the cumulative variance of the eigenvalues to decide upon the number of eigenvectors to be retained after Principle Component Analysis (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcutvFKv0Z-m"
      },
      "source": [
        "### DECIDING THE NUMBER OF PRINCIPLE COMPONENTS\n",
        "\n",
        "# Finding Cumulative Sum of eigenvalues\n",
        "cummulative_sum = np.cumsum(sorted_values)/np.sum(sorted_values)\n",
        "\n",
        "x_axis = range(1,len(sorted_values)+1)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(x_axis, cummulative_sum)\n",
        "plt.xlabel(\"Number of Principle Components\")\n",
        "plt.ylabel(\"Cummulative Variance \")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xy2SPSMMQ7e"
      },
      "source": [
        "Based on the graph, choose an appropriate value of K. Then, reduce the data by finally applying the last step of PCA. At the end of this block, we have the final reduced eigenvectors from the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgbX1ofc1WPT",
        "outputId": "da7a9ecf-5bad-468e-ff33-3e19dddd0918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "### REDUCING THE DATA ###\n",
        "K = 300\n",
        "\n",
        "reduced_data = np.array(sorted_vectors[:K]).transpose()\n",
        "print(\"Reduced Data Dimensions: {}\".format(reduced_data.shape))\n",
        "\n",
        "final_eigen_vectors = np.dot(normalised_X_train.transpose(),reduced_data)\n",
        "print(\"Final Eigen Vectors Dimensions: {}\".format(final_eigen_vectors.shape))\n",
        "\n",
        "# Finding weights for each training image\n",
        "train_weights = np.array([np.dot(i,final_eigen_vectors) for i in normalised_X_train])\n",
        "print(\"Train Weights Dimensions: {}\".format(train_weights.shape))\n",
        "\n",
        "final_eigen_vectors = np.transpose(final_eigen_vectors)\n",
        "\n",
        "### FINAL EIGENVECTORS ARE READY ###"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reduced Data Dimensions: (2538, 300)\n",
            "Final Eigen Vectors Dimensions: (2500, 300)\n",
            "Train Weights Dimensions: (2538, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUvMVuGdMuto"
      },
      "source": [
        "The below is a helper function for calculating the accuracy of the eigenfaces approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWamnS8GDlFr"
      },
      "source": [
        "def display_compare(test_img,predicted_index,test_index):\n",
        "    test_img = np.reshape(test_img,(-1,100))\n",
        "    actual_label = y_test[test_index]\n",
        "    # print(\"Actual Label: {}\".format(actual_label))\n",
        "    # cv2_imshow(test_img)\n",
        "\n",
        "    predicted_image = np.reshape(X_train[predicted_index],(-1,100))\n",
        "    predicted_label = y_train[predicted_index]\n",
        "    # print(\"Predicted Label: {}\".format(predicted_label))\n",
        "    # cv2_imshow(predicted_image)\n",
        "\n",
        "    if predicted_label == actual_label:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0   "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8yPOyRlNxPJ"
      },
      "source": [
        "# Testing the algorithm for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuKknGcB-Gwb",
        "outputId": "bb4e4bf3-11c4-43b0-aaea-26e3238cc323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "correct = 0\n",
        "for i in tqdm(range(len(X_test))):\n",
        "    img = X_test[i]\n",
        "    norm_img = img - mean_face\n",
        "    weights = np.array([np.dot(norm_img,final_eigen_vectors[k]) for k in range(final_eigen_vectors.shape[0])])\n",
        "    weight_error = train_weights - weights\n",
        "    norms = np.linalg.norm(weight_error,axis = 1)\n",
        "    predicted_index = np.argmin(norms)\n",
        "    correct = correct + display_compare(img,predicted_index,i)\n",
        "\n",
        "accuracy = correct*100/(i+1)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 635/635 [00:10<00:00, 62.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "557\n",
            "Accuracy: 87.72%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iJ84Hx9vEqD"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "def prepare_pos_images():\n",
        "    if not os.path.exists(\"pos\"):\n",
        "        os.mkdir(\"pos\")\n",
        "    else:\n",
        "        print(\"Pos Exists. Deleting Directory\")\n",
        "        shutil.rmtree(\"pos\")\n",
        "        os.mkdir(\"pos\")\n",
        "\n",
        "    img_num = 0\n",
        "    for f in os.listdir('training-synthetic'):\n",
        "        try:\n",
        "            print(f)\n",
        "            img = cv2.imread('training-synthetic/'+f,cv2.IMREAD_GRAYSCALE)\n",
        "            resized_img = cv2.resize(img,(100,100))\n",
        "            cv2.imwrite(\"pos/\"+str(img_num)+\".jpg\",resized_img)\n",
        "            img_num += 1\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "# prepare_pos_images()\n",
        "\n",
        "def prepare_neg_images():\n",
        "    if not os.path.exists(\"neg\"):\n",
        "        os.mkdir(\"neg\")\n",
        "    # else:\n",
        "    #     print(\"Neg Exists. Deleting Directory\")\n",
        "    #     shutil.rmtree(\"neg\")\n",
        "    #     os.mkdir(\"neg\")\n",
        "\n",
        "    # neg_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03183080'\n",
        "    # neg_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03563967'\n",
        "    # neg_link = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04576211'\n",
        "    neg_link = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n01905661'\n",
        "\n",
        "\n",
        "    urls = urllib.request.urlopen(neg_link).read().decode()\n",
        "\n",
        "    img_num = 1520\n",
        "\n",
        "    for i in urls.split(\"\\n\"):\n",
        "        try:\n",
        "            print(i)\n",
        "            dir = '/content/drive/My Drive/:p Sem ki naiya hai Ram ke bharose!!/ES331: Probability and Random Processes/Assignment2_Udit/neg/'\n",
        "            urllib.request.urlretrieve(i,dir+str(img_num)+\".jpg\")\n",
        "            img = cv2.imread(dir+str(img_num)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n",
        "            resized_img = cv2.resize(img,(100,100))\n",
        "            cv2.imwrite(dir+str(img_num)+\".jpg\",resized_img)\n",
        "            img_num+=1\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "prepare_neg_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyOBk5k3sHlr"
      },
      "source": [
        "\n",
        "# y_pred = clf.predict(X_test_pca)\n",
        "# print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# # Visualization\n",
        "# def plot_gallery(images, titles, h, w, rows=3, cols=4):\n",
        "#     plt.figure(figsize = (10,10))\n",
        "#     for i in range(rows * cols):\n",
        "#         plt.subplot(rows, cols, i + 1)\n",
        "#         plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
        "#         plt.title(titles[i])\n",
        "#         plt.xticks(())\n",
        "#         plt.yticks(())\n",
        " \n",
        "# def titles(y_pred, y_test, target_names):\n",
        "#     for i in range(y_pred.shape[0]):\n",
        "#         pred_name = target_names[y_pred[i]].split(' ')[-1]\n",
        "#         true_name = target_names[y_test[i]].split(' ')[-1]\n",
        "#         yield 'predicted: {0}\\ntrue: {1}'.format(pred_name, true_name)\n",
        " \n",
        "# prediction_titles = list(titles(y_pred, y_test, target_names))\n",
        "# plot_gallery(X_test, prediction_titles, h, w)\n",
        "\n",
        "# eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
        "# plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8haTiiCA-ky"
      },
      "source": [
        "### EXTRACTING THE IMAGES IN A USABLE FORMAT ###\n",
        "### YALE FACE DATASET ###\n",
        "\n",
        "!wget https://vismod.media.mit.edu/vismod/classes/mas622-00/datasets/YALE.tar.gz\n",
        "!tar -xvf  'YALE.tar.gz'\n",
        "\n",
        "################################################################################\n",
        "\n",
        "if os.path.exists('faces'):\n",
        "    shutil.rmtree('faces')\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "os.mkdir('faces')\n",
        "\n",
        "for name in os.listdir('YALE/faces'):\n",
        "    if not '.pgm' in name:\n",
        "      img = Image.open('YALE/faces/'+name)\n",
        "      h = int(img.size[0]/3)\n",
        "      w = int(img.size[1]/3)\n",
        "      img = img.resize((h,w))\n",
        "      img.save('faces/'+name+'.jpg')\n",
        "      img = cv2.imread('faces/'+name+'.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "      images.append(img.flatten())\n",
        "      labels.append(int(name.split('.')[0][-2:]))\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(\"Images Array: {}\".format(images.shape))\n",
        "print(\"Labels Array: {}\".format(labels.shape))\n",
        "\n",
        "## THE DATASET IS READY FOR DETECTION"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}